---
created: 2023-10-19T09:28:31 (UTC +02:00)
tags: []
source: https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html
author: 
---

# KPIS Topics

> ## Excerpt
> Q: How do we choose our topic?

Note: We have dropped the previous labelling of the Topics as "difficult" or "easy", because most Topics allow different approaches.
We acknowledge that every student has a different background. That's why we want you to choose a topic which fits your capabilities and interests. Therefore, we highly encourage you to pick  a task that you personally consider doable but still a challenge. Don't miss the opportunity to learn something exciting by staying in your comfort zone. 
Additionally, you will get 'suggested approaches' accompanied with code. These lead you to straight-forward (but suboptimal) solutions very quickly. Once you have implemented this approach, it is entirely up to you how you proceed. You can focus on the evaluation, compare different datasets/domains, improve your current approach or try a different one.

---
KPIS Seminar Topic Selection 2023/24

## List of Topics

#### Environmental Learning

1.  [Model-free Reinforcement Learning](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r1)
2.  [Continuous-Action Reinforcement Learning with CACLA](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r2)
3.  [Model-based Reinforcement Learning](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r3)
4.  [Inverse Reinforcement Learning](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r4)
5.  [Curious Exploration of Continuous Spaces](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r5)
6.  [Continous Sequence Generation](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r6)
7.  [Supervised Learning in Meta-World](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r7)
8.  [Planning in Discrete Spaces](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r8)
9.  [Integrate Planning on a State Machine](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r9)
10.  [Search Algorithms](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-r10)

#### Natural Language Processing

11.  [Language Modeling, Traditional Style](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l1)
12.  [Text Generation](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l2)
13.  [LLM with LSTM](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l3)
14.  [Poem Generation, Traditional Style](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l4)
15.  [Build a Chatbot, Traditional Style](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l5)
16.  [LLM Chatbot](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l6)
17.  [Visual Dialogue Generation, LLM-based](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l7)
18.  [Text Summarization](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l8)
19.  [LLM Chain of Thought Prompting](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l9)
20.  [Automated Spell Checking](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l10)

#### Document Classification

23.  [Question Answering, Traditional Style](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l11)
24.  [Visual Question Answering, Traditional Style](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-l12)
25.  [Spam Detection](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c1)
26.  [Document Classification](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c2)
27.  [Document Clustering](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c3)
28.  [Sentiment Analysis on Twitter](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c4)
29.  [Sentiment Analysis of Reviews](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c5)
30.  [Part-of-Speech Tagging](https://www2.informatik.uni-hamburg.de/weber/KPIS/KPIS_Topics_2023.html#section-c6)

___

## Intro

Q: How do we choose our topic?  
Note: We have dropped the previous labelling of the Topics as "difficult" or "easy", because most Topics allow different approaches. We acknowledge that every student has a different background. That's why we want you to choose a topic which fits your capabilities and interests. Therefore, we highly encourage you to pick a task that you personally consider doable but still a challenge. Don't miss the opportunity to learn something exciting by staying in your comfort zone. Additionally, you will get 'suggested approaches' accompanied with code. These lead you to straight-forward (but suboptimal) solutions very quickly. Once you have implemented this approach, it is entirely up to you how you proceed. You can focus on the evaluation, compare different datasets/domains, improve your current approach or try a different one.

Q: Are we allowed to use code from the internet?  
A: Yes, if the license permits it. You are however required to give a reference (URL + author) in the source comments and reference it in your paper where appropriate (e.g. when you take someone's open sourced code to compare your approach). We take plagiarism very serious, both for paper references and code. Always be honest and transparent about your sources.

Q: Are we allowed to use ChatGPT, Bard, Phind, etc. for coding?  
A: Yes. You must state that and how you used it, similarly as you give reference to code from the internet. Clarify your own contribution. Always be honest and transparent about your sources.

Q: What if we have mediocre results in the end or our system doesn't work well?  
A: Failure is part of any progress. If you hit a wall, we expect you to keep trying. If you end up with bad results anyway, this is still a valuable scientific contribution. Explain in your paper and presentation why your approach didn't work so others don't repeat the same mistakes.

Q: What is the purpose of the weekly presence hours?  
A: The presence hours can be used for coding, coordination, questions, research, brain storming, status updates etc. It is necessary to additionally coordinate with your partner regularly outside of the weekly meetings in order to not fall behind the schedule. Effective communication can save you a lot of time so try to organize and split up the work.

Q: Can I pitch my own idea?  
A: If your idea doesn't fit any of the offered categories but is in the scope of the course topics, you can ask us per mail - provided you're already organized into a group. Be prepared to write a short proposal (200-400 words) explaining your problem description, datasets, methodology (algorithm, existing code), and evaluation plan.

Q: I have a different question.  
A: Please contact: cornelius.weber@uni-hamburg.de

#### Core Frameworks and Data Used in the Course

For deep learning:

-   [](https://pytorch.org/)most recommended
-   [](https://www.tensorflow.org/)
-   [](https://keras.io/)

To observe neural network learning progress and organize results:

-   [](https://www.tensorflow.org/tensorboard/)works also with PyTorch
-   [](https://wandb.ai/)"Weights and Biases", better organization using tags

For visualization of results:

-   [](https://matplotlib.org/stable/gallery/index)
-   [](https://seaborn.pydata.org/)

General ML algorithms for preprocessing, clustering, classification:

-   [](http://scikit-learn.org/stable/auto_examples/index.html)

For natural language processing tasks:

-   [](http://www.nltk.org/)has long been _the_ reference in NLP (wrapper for Scikit-Learn: nltk.classify.scikitlearn)
-   [](https://spacy.io/)has performant algorithms
-   [](https://huggingface.co/)models and datasets for deep learning
-   [](https://docs.langchain.com/docs/)framework and tools for large language models (LLMs)

For reinforcement learning:

-   [](https://gymnasium.farama.org/)formerly "OpenAI Gym", provides diverse environments
-   [](https://stable-baselines3.readthedocs.io/en/master/index.html)readily available model-free RL algorithms

Some sources for data

-   [](https://archive.ics.uci.edu/datasets)
-   [](https://www.kaggle.com/datasets)
-   [](http://www.nltk.org/nltk_data)
-   [](http://academictorrents.com/)
-   [](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research)

#### General Advice

All python packages should be installed with pip. If you want to extend a certain package, clone it directly from the project's repository (GitHub) into your working directory. Alternatively, use virtualenv which makes everything much easier.

Check the framework repositories for more up-to-date versions in case you encounter potential bugs. If you have difficulty getting started in a framework, always consult the online documentations and any respective GitHub/Google groups if available.

Write clear and simple code comments. Add meaningful comments where possible. Coming back to something you wrote last week only to waste time trying to figure out your own (or partner's) thought process from earlier is a bad experience.

___

## The Topics

### 1\. Model-free Reinforcement Learning

Stable-Baselines3 is a collection of model-free RL algorithms \[1\]. Start with any of these algorithms, e.g. PPO \[2\] where you will find the example code implemented with the Gymnasium (formerly OpenAI Gym) environment. Typically, the cart-pole balancing task is preset, which is a simple introductory control task for RL \[3\]. Gymnasium lets the agent interface in the same way in all tasks: when the RL model is instantiated, it receives the required information from the environment, such as dimensionalities of observation and action, to allow automatic setting of the model's input and output sizes. The environment's _step_ function receives the action from the agent and returns the observation, reward, and a termination flag. That way, you can quickly switch tasks by editing the environment name in just one line in the Python code.

When it comes to first RL implementations, which usually come with the cart-pole task, there is much more code on the web. Here is a basic implementation \[4\] solving this task and the respective tutorial \[5\]. As you can see, the simplest approach is random search which you can use as a baseline. The other two approaches are based on policy gradient methods with which you can experiment. However, a more typical approach is to reward individual actions instead of policies. The most well known method is Q-Learning. Using the given resources, implement a Q-Learning agent and evaluate it on the cart-pole task.

There are multiple implementations available through GitHub. However, be careful to test the code thoroughly as it might have bugs (always check how many people were able to reproduce the results). Using this Q-Learning implementation, you can modify it into SARSA, which is only a small modification away. There exist old implementations of deep RL with Keras and OpenAI Gym. One works directly with Keras and implements the DQN algorithm step by step \[6\]. Another uses a library called keras-rl \[7\] which combines both on a very high-level interface. Keep in mind to disable animation rendering since it slows down training considerably.

Yet another recent RL library, d3rlpy \[8\] specializes on offline learning, i.e. where RL is performed based on a replay buffer containing prior collected interaction data.

-   \[1\][](https://stable-baselines3.readthedocs.io/)
-   \[2\][](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)
-   \[3\][](https://gymnasium.farama.org/environments/classic_control/cart_pole/)
-   \[4\][](https://github.com/kvfrans/openai-cartpole)
-   \[5\][](http://kvfrans.com/simple-algoritms-for-solving-cartpole/)
-   \[6\][](https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/)
-   \[7\][](https://github.com/matthiasplappert/keras-rl)
-   \[8\][](https://takuseno.github.io/d3rlpy/)

### 2\. Continuous-Action Reinforcement Learning with CACLA

The Continuous Actor-Critic Learning Automaton (CACLA) is a simple, model-free continuous-action reinforcement learning algorithm \[1\]. Its code in PyTorch is available as a result of last year's KPIS seminar work and features an integrated GUI and a very simple environment for first experiments \[2\].

One desirable goal would be to try out CACLA with other environments, such as from Gymnasium (aka. OpenAI Gym) \[3\]. A more ambitious goal would be to compare CACLA against other algorithms, e.g. from Stable-Baselines3 \[4\].

-   \[1\][](https://www2.informatik.uni-hamburg.de/weber/KPIS/Cacla.html)
-   \[2\][](https://www2.informatik.uni-hamburg.de/weber/KPIS/CACLA2.tar)
-   \[3\][](https://gymnasium.farama.org/)
-   \[4\] [](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html)(the table column "Box" means continuous action)

### 3\. Model-based Reinforcement Learning

Unlike model-free RL, model-based RL learns the world state transition model _s' = P(s,a)_, which allows planning into the future. For easy access, we recommend Temporal Difference Model Predictive Control (TD-MPC) \[1\]. This model is very performant and the code is already linked with DeepMind Control Suite \[2\] with MuJoCo-simulated 3D control tasks. The most ambitious is a Humanoid that you may get to walk after around 24h of training. You will notice that it walks weirdly, e.g. alternating between forward and sideways walking, which may inspire to elaborate the reward function.

Other popular model-based RL algorithms are the discrete-action MuZero \[3\] and the continuous-action DreamerV3 \[4\]. However, WTM PhD students recommend abovementioned TD-MPC as easiest to understand. Models differ e.g. by using different internal predictive models (recurrent (Dreamer) or feedforward (MuZero, TD-MPC); stochastic (Dreamer) or deterministic (MuZero, TD-MPC)) or different planners (e.g. cross entropy method CEM (Dreamer, TD-MPC) or Monte Carlo Tree Search (MuZero)).

-   \[1\] [](https://nicklashansen.github.io/td-mpc/)(PyTorch, recommended)
-   \[2\][](https://github.com/deepmind/dm_control/)
-   \[3\] [](https://github.com/werner-duvaud/muzero-general)(PyTorch)
-   \[4\] [](https://danijar.com/project/dreamerv3/)(JAX)

### 4\. Inverse Reinforcement Learning

In IRL, the agent observes another actor performing action sequences, but has no access to the reward. Aim is to estimate the reward / value function that underlies the actor's decisions. Compared to supervised learning of the sequences directly, IRL promises better generalization with fewer seen examples.

Paper \[1\] is probably the best understandable introduction to IRL. It has been implemented \[2\], and the modernized code \[3\] contains two working variants in a simple gridworld environment: maxent\_irl\_gridworld.py and the deep learning variant deep\_maxent\_irl\_gridworld\_v2.py. Experimenting with this code shall lead to a better understanding of IRL.

An evaluation, if time permits, could be done by comparing the IRL learner with another that learns the action trajectories with supervised learning.

-   \[1\] Maximum Entropy Deep Inverse Reinforcement Learning (2016)
-     [](https://arxiv.org/pdf/1507.04888.pdf)
-   \[2\] [](https://github.com/yrlu/irl-imitation)(Python2, Tensorflow1)
-   \[3\] [](https://www2.informatik.uni-hamburg.de/weber/KPIS/irl-imitation-v2.tar)(Python3; TensorFlow1 with compatibility directives)

### 5\. Curious Exploration of Continuous Spaces

One particular challenge in RL is to sample the entire state space representatively, specifically for world model training or in the absense of rewards (for task-independent exploration). To let the agent explore yet unvisited regions, the Plan-to-explore model \[1\] trains an ensemble of world models. When planning with these models, their predictions will be inconsistent in regions that have not yet been learnt well. These inconsistencies are used to construct a curiosity reward, which gives the model incentives to explore more those regions.

Aim in this topic is to investigate the exploration mechanism. Can exploration be confined to promising areas, so not to waste time in vast uninteresting regions of high-dimensional spaces?

-   \[1\] Planning to Explore via Self-Supervised World Models (2020)
-     [](https://ramanans1.github.io/plan2explore/) (TensorFlow)
-     [](https://github.com/yusukeurakami/plan2explore-pytorch) (PyTorch)

### 6\. Continous Sequence Generation

A policy in RL typically outputs a single action vector _a_ given a state _s_. However, many movements, such as eye-, gaze-, or arm movements, are characterized by a temporal evolution of forces and accelerations. These transient control patterns are open-loop controlled, since they are too fast to read feedback from sensory inputs during their execution. Instead, they optimize some objective, such as reaching a desired state _s'_ quickly while keeping forces small. RL does not model this because it involves a feedback cycle at every action, i.e. implementing closed-loop control.

The goal in this topic is to devise a model that generates the trajectory of some actor in continuous space, without feedback. An example is a model of gaze control \[1\]. A new application for example for a robot arm movement would be desirable. The example model's code \[2\] is written in C, so a translation to Python, preferentially using autodifferentiation via PyTorch, is also desirable.

Alternative methods for continuous trajectory optimization are Particle Swarm Optimization \[3\] or the Cross-Entropy Method \[4\].

-   \[1\] Learning the Optimal Control of Coordinated Eye and Head Movements.
-     [](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002253)
-   \[2\][](https://www.informatik.uni-hamburg.de/weber/KPIS/eyehead.cpp)
-   \[3\][](https://en.wikipedia.org/wiki/Particle_swarm_optimization)
-     [](https://medium.com/analytics-vidhya/implementing-particle-swarm-optimization-pso-algorithm-in-python-9efc2eb179a6)
-   \[4\][](https://pypi.org/project/cross-entropy-method/)

### 7\. Supervised Learning in Meta-World

Meta-World \[1\] is a benchmark comprising 50 manipulation environments, originally designed for multi-task reinforcement learning. Here we want to get familiar with it by using it for simple supervised learning, namely classification of the action. Moreover, instead of a classification into 50 distinct classes, we would like to describe the different tasks compositionally using a small number of reusable words (e.g. nouns and verbs like "lever", "handle" and "push", pull") by adapting the labels as far as possible. A suitable model that performs compositional classification on video inputs exists, including PyTorch source code \[2\].

-   \[1\][](https://meta-world.github.io/)
-   \[2\][](https://www2.informatik.uni-hamburg.de/wtm/publications/2022/VLWW22/ICANN_Paper_Caspar_Volquardsen_Compositional_Generalization_in_Multimodal_Language_Learning_revised_.pdf)
-     [](https://github.com/Casparvolquardsen/Compositional-Generalization-in-Multimodal-Language-Learning)

### 8\. Planning in Discrete Spaces

Start by investigating the code for STRIPS \[1\] and try to understand how the planner works by experimenting with the toy examples and the code base.

Once you get a hang of the basics, compare it with one or more other planners: _(i)_ Use the code as a basis to implement GraphPlan \[2\]. Come up with an experimental setup and task that allows you to compare both algorithms. Find out how you can measure the performance of your planners. _(ii)_ Have a look at SHOP \[3\], a HTN planning system. _(iii)_ Compare with an **LLM**, e.g. describe a simple problem to ChatGPT and let it return the plan. Can it solve the same example problems?

-   \[1\] [](https://github.com/tansey/strips)STanford Research Institute Problem Solver
-   \[2\][](http://www.cs.cmu.edu/~avrim/graphplan.html)
-   \[3\] [](https://www.cs.umd.edu/projects/shop/)Simple Hierarchical Ordered Planner

### 9\. Integrate Planning on a State Machine

Start by getting familiar with two paradigms: First, investigate the STRIPS planning system \[1\] and try to understand how the planner works by experimenting with the toy examples and the code base. Second, get familiar with a state machine, for which SMACH \[2\] is a commonly used software (it is distributed under ROS, but can run on itself without ROS).

A state machine determines how states transition into other states. The result of a planner, i.e. a plan, could be written as a state machine. The idea of this project is to replace the transitions between states in SMACH by preconditions and effects, so that states could be flexibly linked by a planner instead of hardwired with transitions. Implementation-wise, this could be done by a planner linking the states and exporting the resulting state machine as SMACH code.

-   \[1\][](https://github.com/tansey/strips)
-   \[2\][](http://wiki.ros.org/smach)

### 10\. Search Algorithms

The goal is to implement different search algorithms, visualize their pathfinding, and provide a comparison. A good final outcome would be something like \[1\]. The animations can be created using matplotlib or the console and need not be interactive, e.g. with randomly generated worlds.

Since these algorithms are classic, large language models (LLMs), i.e. ChatGPT and friends, may be well suitable to do part of the programming.

-   \[1\][](http://qiao.github.io/PathFinding.js/visual/)

___

### 11\. Language Modeling, Traditional Style

Language Models (LMs) are required for a number of different NLP tasks. Here, your objective is to get an understanding of language modeling by implementing an n-gram LM from scratch. For the fundamentals, you can have a look at \[1\] (based on Jurafsky's book). Start by creating a trainer for unigram models and implement perplexity and coverage evaluations using separate testing data (see \[2\] for some pseudocode and all formulas you should need). At the beginning you should work with small amounts of input text for the purpose of debugging. Once you feel confident about your model, you can take any other text corpus.

As a next step, implement a bigram model. If possible, keep the implementation general, so you can switch to n-grams with n≥3 at any time. While bigrams can be extracted with NLTK, it doesn't currently provide an interface for language modeling. You can have a look at the old implementation, however, to get a general idea \[3\]. As a final step, learn about smoothing and improve your model.

-   \[1\][](https://web.stanford.edu/class/cs124/lec/lm2021.pdf)
-   \[2\][](http://www.phontron.com/slides/nlp-programming-en-01-unigramlm.pdf)
-   \[3\][](http://www.nltk.org/_modules/nltk/model/ngram.html)

### 12\. Text Generation

This task consists of _(i)_ finding or generating a text corpus, _(ii)_ training a language model and _(iii)_ generating text from this model.

For the corpus you can choose a specific domain (e.g. news, tweets, jokes, reviews, screenplays, emails). Currently popular language models are n-grams and recurrent neural networks (RNNs). Bigrams are implemented in nltk.Text.generate and can be easily extended to trigrams etc by taking this function's source as a starting point (you can also use gensim \[1\]). Once you have a language model, generation is straight-forward as you'll simply predict the next most likely character or word based on the previous prediction (think of autocomplete that keeps guessing based on its own guesses instead of your input).

The winning language model architecture nowadays is however the Transformer-based **LLM**, a feedforward network with an attention mechanism that acts as a strong non-linearity. One of the smallest available pretrained open source models is the T5 \[2\]; yet, its smallest version (t5-small) still has 60.5M parameters. So, people usually do not train one, but import a pretrained network and use it either as is (frozen) or merely fine-tune it for a specific task.

Transformers mostly use token embeddings \[3\], although character- or word embeddings would be feasible as well. Interesting would be to compare these embeddings, e.g. train a small LLM with different embeddings and evaluate its performance.

-   \[1\][](https://radimrehurek.com/gensim/models/phrases.html)
-   \[2\][](https://huggingface.co/collections/google/t5-release-65005e7c520f8d7b4d037918)
-   \[3\][](https://en.wikipedia.org/wiki/Byte_pair_encoding)

### 13\. LLM with LSTM

Before using Transformers, OpenAI used a long short-term memory (LSTM) recurrent neural network (RNN) for their large language model \[1\]. The network, trained to predict the next character, can generate text fairly well, but not comparable to the much larger Transformer-based ChatGPT. Interestingly, a **sentiment neuron** was found in this RNN: the sentiment of the input text determines the neuron's activity, and the neuron's activity controls the sentiment of the generated text.

Aim of this project is to recapitulate these seminal experiments. Can you find the sentiment neuron? Do other neurons encode other identifiable concepts? For an early example of character-level language modeling with RNNs, see Karpathy's blog post \[2\] and lstm\_text\_generation.py in Keras \[3\]. These LSTMs can be trained from scratch as they are not so large. You could also experiment whether token embeddings, as used in the transformer architectures, can lead to better performance.

For the best of both worlds, RNNs and the Transformer, check out the Universal Transformer \[4\].

-   \[1\][](https://openai.com/blog/unsupervised-sentiment-neuron/)
-     [](https://github.com/openai/generating-reviews-discovering-sentiment) (Tensorflow)
-     [](https://github.com/guillitte/pytorch-sentiment-neuron) (PyTorch)
-   \[2\][](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
-   \[3\][](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)
-   \[4\][](https://github.com/andreamad8/Universal-Transformer-Pytorch)

### 14\. Poem Generation, Traditional Style

This task is similar to the "Text Generation" task but differs in that the produced language has to meet more specific criteria. This allows for a number of heuristics to generate "realistic" poetry. A good example of a poetry generator can be found in \[1\]. This generator uses NLTK and can consider e.g. different rhyme schemes and count syllables. You can start by investigating this framework for ideas before starting with your own program.

Generally, you can either build a language model and constrain the generated text somehow or try to "translate" the input text into a "poem language". The latter approach is the easier one: start by simply restructuring the input text without changing the words (count syllables and break the line when appropriate, see \[2, slides 49-56\]). Then, you can gradually increase the complexity by e.g. querying wordnet/conceptnet for similar words and exchanging them, making the output more different.

Or you can build a simple context-free grammar (CFG) which is a very simple method but can produce some very good results. You can define your own CFG and generate texts very easily with NLTK \[3\].

-   \[1\][](https://github.com/nathanielksmith/prosaic)
-   \[2\][](http://shankarambady.com/nltk.pdf)
-   \[3\][](http://www.nltk.org/howto/generate.html)

### 15\. Build a Chatbot, Traditional Style

Before LLMs, chatbots were simple, built e.g. in nltk.chat \[1\], using Python conditional statements to encode conversational heuristics like brobot \[2\], or using Artificial Intelligence Markup Language (AIML) \[3\]. Alternatively, open source conversational AI platforms, like PyDial \[4\], DeepPavlov \[5\] or the commercial Rasa \[6\], provide components for building chatbot assistants. Such a system can become a language-enhanced user interface to some data base.

An early approach training a language model on dialog corpora is the "neural conversational model" \[7\], where the dataset will give your bot a unique character. A more complex approach includes reinforcement learning to complete a movie-ticket booking task \[8\].

To evaluate your progress, you can log conversations between your bot and other (ideally more sophisticated) bots.

-   \[1\][](http://www.nltk.org/_modules/nltk/chat.html)
-   \[2\] [](https://lizadaly.com/brobot/)(formerly: [](https://github.com/lizadaly/brobot/))
-   \[3\][](http://www.devdungeon.com/content/ai-chat-bot-python-aiml)
-   \[4\][](https://pydial.cs.hhu.de/)
-   \[5\] [](https://deeppavlov.ai/)(uses PyTorch)
-   \[6\][](https://rasa.com/docs/rasa/playground)
-   \[7\] [](https://github.com/Conchylicultor/DeepQA)(TensorFlow)
-   \[8\][](https://github.com/MiuLab/TC-Bot)

### 16\. LLM Chatbot

Nowadays, trained chatbots surround us in the form of LLMs like ChatGPT. Langchain is a programming framework around LLMs, for example for dialogue \[1\]. It provides tools for holding the conversation context in memory or accessing external data.

Interfacing with databases is straightforward, since the commercial LLMs are fluent with SQL and other data types, like with many programming languages. Upon your prompt, an LLM will easily generate a database of a desired format, empty or filled with phantasy data. Instructions about interfacing LLMs with databases are numerous, here is one using langchain \[2\]; here is another with an own database example \[3\]. One idea could be to interface the Menu of the Stellingen Cafeteria \[4\] using an RSS API, or, an LLM may just read the web-page like a human, to answer questions like "What are today's vegetarian choices?".

-   \[1\][](https://python.langchain.com/docs/use_cases/chatbots/)
-   \[2\][](https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2)
-   \[3\][](https://www.clearpeaks.com/creating-a-chatbot-based-on-chatgpt-for-interacting-with-databases/)
-   \[4\][](https://www.inf.uni-hamburg.de/en/service/mensa.html)

### 17\. Visual Dialogue Generation, LLM-based

How can a pure LLM consider images? An early approach, which worked when LLMs were purely linguistic, is by providing the image description to the LLM as text. To this end, an image recognition model, such as Yolo \[1\] or ViLD \[2\] could be implemented, and its output suitably passed on to the LLM. More sophisticated approaches exist, e.g. \[3\]. A working image-LLM integration would be a success, yielding both, a **visual question answering** and dialog generation system, due to the flexibility of LLMs.

As a further step, the image could display the state of a game. For example, in a visual guessing game, one of several fields needs to be guessed by using a suitable question strategy. Since language models of insufficient scale lacked any planning and goal-seeking abilities, this had to be done by reinforcement learning \[4\]. With recent LLMs, we found that when prompting the game rules, the LLM can play the full game with its planning ability. The focus here, though, is the vision extension.

-   \[1\][](https://github.com/ultralytics/ultralytics)
-   \[2\][](https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild)
-   \[3\][](https://github.com/salesforce/LAVIS/tree/main/projects/img2llm-vqa)
-   \[4\] Word-by-Word Generation of Visual Dialog using Reinforcement Learning
-     [](https://www2.informatik.uni-hamburg.de/wtm/publications/2022/LWBW22/2022-07-11_ICANN_paper_revised_.pdf)
-     [](https://github.com/ylysa/Recurrent-Attention-Model)

### 18\. Text Summarization

Extractive and abstractive summarization are the two main approaches to the task of automatically summarizing paragraphs into smaller chunks of text.

_Extractive summarization_ builds the summary from sentences/phrases that contain important keywords. This approach is easy and can be done with standard NLP techniques. See the NLTK book chapter 7 for a tutorial on information extraction \[1\]. For your own algorithm, you can have a look at \[2\] and investigate the respective implementation. The writeup also features some ideas for future work which you can focus on. There are even simpler approaches like \[3\]. As you can see, a naive summarizer can be implemented in a few lines of code using NLTK. Try to implement a better summarizer where the output isn't an exact copy of parts of the input. You will notice that an approach may work on short text passages, but fail on large books (and vice versa). Therefore, it might be useful to stick to a specific type of text.

_Abstractive summarization_ builds an internal semantic representation to generate a more abstract summary. For this approach to text summarization, a neural network toolkit like \[6\] can be used, or there exists code to a research paper on lecture summarisation \[7\] and its generalisation \[8\].

_LLMs_ like ChatGPT easily do (abstractive) summarization for you. However, an LLM can process only a limited number of input tokens. The token limits are, for example, for gpt-35-turbo 4096 tokens, for gpt-4 8192 tokens, for gpt-4-32k 32768 tokens. A book would be too large. To summarize a book (that isn't already known to the LLM), we could partition it into small chunks that fit into the LLMs input, summarize them and then concatenate the resulting summaries. We will then summarize these for the book summary (or if still too long, recursively proceed until we yield just one summary). This would require to write a program to be interfaced with an existing pretrained LLM. Instructions \[9\] and frameworks exist, e.g. langchain \[10\] which has many tools, such as a text splitter. Needless to say, there are industry solutions considering large inputs \[11\].

_Evaluation_ of your summaries might be by human rankings. However, this method can be quite subjective unless you perform a proper user study with an appropriate sample size. Luckily, there exist Evaluation Measures for Text Summarization \[4\]. Consider implementing some of these metrics early on, so you can evaluate a large number of samples without checking the quality of your summaries manually each time you change your system. You can also use gensim's implementation (based on TextRank) for comparison \[5\].

-   \[1\][](http://www.nltk.org/book/ch07.html)
-   \[2\][](https://thetokenizer.com/2013/04/28/build-your-own-summary-tool/)
-   \[3\][](https://github.com/thavelick/summarize/blob/master/summarize.py)
-   \[4\][](http://www.cai.sk/ojs/index.php/cai/article/viewFile/37/24)
-   \[5\][](http://rare-technologies.com/text-summarization-with-gensim/)
-   \[6\][](https://github.com/pytorch/fairseq)
-   \[7\][](https://github.com/dmmiller612/lecture-summarizer)
-   \[8\][](https://github.com/dmmiller612/bert-extractive-summarizer)
-   \[9\][](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt)
-   \[10\][](https://github.com/langchain-ai/langchain)
-   \[11\][](https://www.anthropic.com/index/100k-context-windows)

### 19\. LLM Chain of Thought Prompting

LLMs can reason, i.e. perform multiple logical steps to answer some complex questions. Wrong answers to a pure question can sometimes be corrected by adding "Let's think step-by-step" to the prompt, which lets the LLM elaborate its chain of thought. However, one can tease even more out of LLMs. "Tree of Thoughts" enables exploration by considering multiple different reasoning paths and evaluating them \[1\]. "Automatic Chain of Thought Prompting" automatically generates demonstrations of diverse reasoning chains as examples for the LLM \[2\]. Microsoft's "guidance" framework \[3\] (alternative to Langchain) features a Domain Specific Language for easy LLM interaction addressing also chain of thoughts. All these softwares require an openai-api key to let you interface with GPT. The goal of this project is to get familiar with LLM interfacing by programming while getting most out of LLMs.

-   \[1\][](https://github.com/kyegomez/tree-of-thoughts)
-   \[2\][](https://github.com/amazon-science/auto-cot)
-   \[3\][](https://github.com/microsoft/guidance)

### 20\. Automated Spell Checking

Start off by reading the tutorial by Russel Norvig \[1\]. Comprehend the presented approach and experiment with the provided code while thinking about drawbacks and possible improvements. This approach is mostly based on simple typo heuristics and matching versus a dictionary. Test the robustness of this method by looking for a corpus of spelling mistakes (e.g. \[2\]) and identify which types of mistakes are detected and which are ignored.

For a comparison with a good spell checker, have a look at PyEnchant \[3\], which wraps Enchant \[4\], or other freely available software. Besides improving your system, you can also extend it with related functionality such as grammatical errors or bad writing style. For a general overview of methods have a look at \[5\]. As an example why grammar is important, consider the problem of "weather vs. whether" where the correct spelling depends on grammar. This can be solved by PoS taggers (use NLTK) or other standard techniques.

Another idea of spell checkers would be to use (character-based) language models to find the improbable character among the probable ones, but it's not as easy as it appears. chars2vec encodes words robustly but does not correct errors \[6\]. An LSTM extension to JamSpell yielded little improvement \[7\]. An approach with an LLM only replaces tokens but refrains from insertions or deletions \[8\].

If you want to investigate the current (freely available) state of the art, have a look at engines like \[9,10,11\] which provide spelling corrections but also a far more advanced analysis of written text based on structure, word variety, phrasing and more.

-   \[1\][](http://norvig.com/spell-correct.html)
-   \[2\][](https://github.com/EducationalTestingService/toefl-spell)
-   \[3\][](https://sourceforge.net/projects/pyenchant/)
-   \[4\][](https://abiword.github.io/enchant/)
-   \[5\][](http://www.dcs.bbk.ac.uk/~roger/spellchecking.html)
-   \[6\][](https://hackernoon.com/chars2vec-character-based-language-model-for-handling-real-world-texts-with-spelling-errors-and-a3e4053a147d)
-   \[7\][](https://towardsdatascience.com/spelling-correction-how-to-make-an-accurate-and-fast-corrector-dc6d0bcbba5f)
-   \[8\][](https://github.com/jacklxc/StandAloneSpellingCorrection)
-   \[9\][](https://www.slickwrite.com/)
-   \[10\][](https://www.grammarly.com/)
-   \[11\][](https://languagetool.org/)

___

### 21\. Question Answering, Traditional Style

The goal is to build a system that is able to read a few paragraphs of text and then answer questions about it. There are multiple corpora available for QA tasks. An example for the Facebook children's book set can be found in Keras \[1\] which you can use as a starting point. If you want to experiment with an implementation based around NLTK, see \[2\].

You can also choose to work with a search engine instead of a corpus although that makes evaluation more difficult without labeled data. For an example of such a "semantic search engine" see \[3\] which can also be modified to use a learning algorithm instead of a search engine.

Before the general capabilities of LLMs became available, question answering was often simplified to a classification problem where only the correct answer from a selection of _n_ possible answers needed to be returned. The Stanford Question Answering Dataset (SquAD \[2\]) makes another simplification, namely that the answer is a pointer to a word in the paragraph that is asked about. A pretrained language model such as the BERT encoder then reads that paragraph, and a downstream model reads that representation to learn the answer pointer \[5\].

-   \[1\][](http://smerity.com/articles/2015/keras_qa.html)
-   \[2\][](https://github.com/bwbaugh/causeofwhy)
-   \[3\][](http://www.michaelnielsen.org/ddi/how-to-answer-a-question-a-simple-system/)
-   \[4\][](https://rajpurkar.github.io/SQuAD-explorer/)
-   \[5\][](https://blog.paperspace.com/how-to-train-question-answering-machine-learning-models/)

### 22\. Visual Question Answering, Traditional Style

Given an image and a question about the image, the system shall return the correct answer. Just like text-based Question Answering, this problem was expressed as a 1-of-_n_ classification problem, where the answer is only to be selected among a given set of _n_ answers (typically a few dozens), and only the class label is of any relevance to the model while the actual content of the answer is arbitrary. The relevant architectural decisions are _(i)_ how is the image processed (e.g. VGG, ResNet), _(ii)_ how is the question processed (e.g. word- or sentence embeddings), where for both modalities pretrained networks are useful, and _(iii)_ how is the information from the two modalities combined (e.g. attention mechanism).

There are several pedagogical descriptions on the web, e.g. \[1\] with code \[2\]\[3\], also using Transformers, e.g. \[4\]\[5\].

-   \[1\][](https://medium.com/@anuj_shah/visual-question-answering-2350eea072df)
-   \[2\][](https://github.com/anujshah1003/VQA-Demo-GUI)
-   \[3\][](https://towardsdatascience.com/visual-question-answering-with-deep-learning-2e5e7cbfdcd4#e44d)
-   \[4\][](https://medium.com/data-science-at-microsoft/visual-question-answering-with-multimodal-transformers-d4f57950c867)
-   \[5\][](https://github.com/kaylode/vqa-transformer)

### 23\. Spam Detection

Classical frameworks like NLTK can lead a large way toward some basic spam detection. The classical approach is: Label the emails. Use NLTK to strip the corpus of stop-words, extract meaningful features and give them to a classifier (e.g. Naive Bayes, Decision Tree, Neural Network). For a basic example see the tutorial \[4\]. Also, neural network based NLP libraries support text classification \[5\].

Suggested datasets: Start with SpamAssassin's public corpus (6000 mails) \[1\] before moving to the larger TREC 2007 Public Corpus (75k mails) \[2\] or Enron-Spam corpus (200k+ mails) \[3\]. The latter corpus has the benefit of already being preprocessed.

LLM approach: Of course, you can feed an email into ChatGPT and ask whether it is spam. However, for classification, this is suboptimal _(i)_ due to the limited number of input tokens, _(ii)_ since you may want fine-tuning to your specific dataset, and _(iii)_ difficult quantitative evaluation.

In general, **document classification (and clustering)** works as follows: encode the document, e.g. email, using the encoder of an LLM, such as BERT \[6\], and then train a simple classifier (or clustering algorithm) on the obtained representations of the documents. A representation is just a vector of constant size (often 512) containing the document's information such as semantics. This code \[7\] uses the LLM Flan-T5, which exists in various sizes from flan-t5-small with 60.5 million parameters up to flan-t5-xxl with 11.3B parameters \[8\].

-   \[1\][](https://spamassassin.apache.org/old/publiccorpus/)
-   \[2\][](http://plg.uwaterloo.ca/~gvcormac/treccorpus07/)
-   \[3\][](http://www.aueb.gr/users/ion/data/enron-spam/)
-   \[4\][](http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf)
-   \[5\][](https://github.com/flairNLP/flair)
-   \[6\][](https://en.wikipedia.org/wiki/BERT_(language_model))
-   \[7\] [](https://github.com/jpmorganchase/llm-email-spam-detection)(PyTorch)
-   \[7\][](https://huggingface.co/collections/google/flan-t5-release-65005c39e3201fff885e22fb)

### 24\. Document Classification (not updated)

The goal of this task is to classify documents (paragraphs of text) into categories.

A typical task is the Reuters Newswire topic classification task which consists of different news articles and their respective news groups. If you are interested in focusing on neural networks for this task, start with the example in Keras \[1\] which uses a simple Multi-Layer Perceptron. Investigate the code to understand the preprocessing steps (reuters.load\_data) and try different parameters to see if you can improve the accuracy. Have a look at the documentation and see if you can improve your network architecture as well. To avoid Keras and build on the more modern PyTorch, you can also use other neural network libraries for text classification \[2\].

Alternatively, you can use the 20 newsgroups dataset \[3\] in scikit-learn to compare neural networks with other machine learning algorithms (see \[4\]). Be careful to tune parameters properly for each model you train by measuring the performances for a set of different values.

-   \[1\][](https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/reuters_mlp.py)
-   \[2\][](https://github.com/flairNLP/flair)
-   \[3\][](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)
-   \[4\][](https://github.com/scikit-learn/scikit-learn/blob/master/examples/text/plot_document_classification_20newsgroups.py)

### 25\. Document Clustering (not updated)

The goal of this task is to implement a small system that is able to compare documents. This system can then optionally be extended to a recommendation system, search engine, or something different altogether. Alternatively, different clustering techniques can be compared and evaluated.

You will find that the basic required tools are already implemented in both scikit-learn and NLTK. For a tutorial on using both see \[1\] which shows the standard approach of calculating TF-IDF vectors (implemented in scikit-learn and gensim) of documents and computing the (cosine) similarity between them. An example of direct clustering on TF-IDF vectors can be seen in scikit's repository \[2\].

Another approach is to use doc2vec \[3\] to map documents to vectors. There are a number of implementations available, e.g. in gensim \[4\] or tensorflow \[5\]. For a tutorial on the basics, see \[6\] or \[7\].

-   \[1\][](http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html)
-   \[2\][](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html)
-   \[3\][](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)
-   \[4\][](https://radimrehurek.com/gensim/models/doc2vec.html)
-   \[5\][](https://github.com/wangz10/tensorflow-playground/blob/master/doc2vec.py)
-   \[6\][](https://medium.com/towards-data-science/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)
-   \[7\][](http://colah.github.io/posts/2015-01-Visualizing-Representations/)

### 26\. Sentiment Analysis on Twitter (not updated)

Check out a blog \[0\] that aims to get you started with sentiment analysis with transformers.

The goal of this task is to classify chunks of text into "positive" or "negative" sentiments. Begin with getting a labeled corpus. We recommend \[1\] or one of the linked sub-corpora as a start. You can also mine twitter yourself - e.g. using \[2\] which has a small sample script and instructions on how to get a twitter API key (takes around 2 minutes). You can also use NLTK for this \[5,6\]. Tweets you get from Twitter are not annotated but could still be useful for unsupervised learning or further analysis. Next, start with something simple like Naive Bayes (use NLTK, \[3\]) to obtain some baseline results. Your starting accuracy will probably leave a lot of room for improvements. Analyse your data and how language in tweets differs from language on e.g. news articles. Think of possible solutions (see \[2\] for a related paper) and improve your approach. See \[4\] for a NLP toolkit that is specific to Twitter.

-   \[0\][](https://huggingface.co/blog/sentiment-analysis-python)
-   \[1\][](http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/)
-   \[2\][](https://github.com/bwbaugh/twitter-corpus)
-   \[3\][](http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/)
-   \[4\][](https://github.com/aritter/twitter_nlp)
-   \[5\][](http://www.nltk.org/howto/twitter.html)
-   \[6\][](https://github.com/nltk/nltk/tree/develop/nltk/twitter)

### 27\. Sentiment Analysis of Reviews (not updated)

The goal of this task is to classify chunks of text into "positive" or "negative" sentiments (or a rating scale). The stanford movie review corpus with reviews from IMDB offers a good start for this task \[1\]. This corpus has 50k labeled movie reviews. This dataset was part of a Kaggle challenge, so there are a lot of approaches at the challenge website \[2\]. There is also a short tutorial on using word2vec for this task.

If you are interested in using neural networks, you can find multiple examples for the IMDB task in Keras \[3\]. Please note that the data in these examples is already preprocessed. You should also note that these examples might use just a part of the corpus. It might be better to reimplement the preprocessing part yourself on the complete corpus. We recommend starting with simple 1-hidden-layer neural network (MLP) before trying the more advanced architectures presented in the examples. Keep in mind that simple models might train faster and perform similarly well, provided you choose good features beforehand.

Other approaches, e.g. \[4\] use scikit-learn to compare the performance of different algorithms.

-   \[1\][](http://ai.stanford.edu/~amaas/data/sentiment/)
-   \[2\][](https://www.kaggle.com/c/word2vec-nlp-tutorial)
-   \[3\][](https://builtin.com/data-science/how-build-neural-network-keras)
-   \[4\][](https://github.com/Poyuli/sentiment.analysis)

### 28\. Part-of-speech Tagging

Start by going through chapter 5 of the NLTK book \[1\] with the goal of understanding the necessary background on PoS tagging and how it is implemented in NLTK. The chapter will teach you a number of different ways to implement PoS taggers. Build a proper experimental setup in which you can compare some of the taggers found in nltk.tag \[2\] with regard to their accuracy. From there you can expand your evaluation and/or implement your own taggers. You can e.g. use neural networks (Keras, or another new framework \[3\]) or hidden Markov models \[4\]. Alternatively, you can build a Maxent tagger based on the Maxent classifier in NLTK.

To evaluate your taggers, you can use the corpora provided in NLTK (like the Brown corpus used in the book) or search for other free corpora \[5\].

The LLM update to this topic is that the sentence representations of a pretrained LLM, such as the encoder-focused BERT, can be used as input to a simple classifier (e.g. \[6\]\[7\]).

-   \[1\][](http://www.nltk.org/book/ch05.html)
-   \[2\][](https://github.com/nltk/nltk/tree/develop/nltk/tag)
-   \[3\][](https://github.com/flairNLP/flair)
-   \[4\][](https://github.com/hmmlearn/hmmlearn)
-   \[5\][](https://en.wikipedia.org/wiki/Treebank#Syntactic_treebanks)
-   \[6\][](https://github.com/soutsios/pos-tagger-bert)
-   \[7\][](https://github.com/ali-aboelezz/bert-pos-tagging)

___
